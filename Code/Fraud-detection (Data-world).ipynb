{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7291f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, silhouette_score, calinski_harabasz_score, homogeneity_score, completeness_score, v_measure_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import OneClassSVM\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from pandas import DataFrame\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bc38e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Time        V1        V2        V3        V4        V5  \\\n",
       "0           1   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321   \n",
       "1           2   0.0  1.191857  0.266151  0.166480  0.448154  0.060018   \n",
       "2           3   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198   \n",
       "3           4   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4           5   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193   \n",
       "\n",
       "         V6        V7        V8  ...       V21       V22       V23       V24  \\\n",
       "0  0.462388  0.239599  0.098698  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1 -0.082361 -0.078803  0.085102  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  1.800499  0.791461  0.247676  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  1.247203  0.237609  0.377436  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4  0.095921  0.592941 -0.270533  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv('Fraud-detection (Data-world).csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1713cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8e955e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "Time          0\n",
      "V1            0\n",
      "V2            0\n",
      "V3            0\n",
      "V4            0\n",
      "V5            0\n",
      "V6            0\n",
      "V7            0\n",
      "V8            0\n",
      "V9            0\n",
      "V10           0\n",
      "V11           0\n",
      "V12           0\n",
      "V13           0\n",
      "V14           0\n",
      "V15           0\n",
      "V16           0\n",
      "V17           0\n",
      "V18           0\n",
      "V19           0\n",
      "V20           0\n",
      "V21           0\n",
      "V22           0\n",
      "V23           0\n",
      "V24           0\n",
      "V25           0\n",
      "V26           0\n",
      "V27           0\n",
      "V28           0\n",
      "Amount        0\n",
      "Class         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing data\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7cd50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Unnamed: 0', 'Time']\n",
    "data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "336b1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X = data.drop(['Class'], axis = 1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af68f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 0, Count: 284315\n",
      "Value: 1, Count: 492\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a8470",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f8580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cumulative Variance Explained by Principal Components')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.figure()\n",
    "plt.plot(cumsum)\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Variance Explained')\n",
    "plt.title('Cumulative Variance Explained by Principal Components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456a3549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components needed to retain 95% of the variance is equal to : 24\n"
     ]
    }
   ],
   "source": [
    "dim_95 = np.argmax(cumsum >= 0.85) + 1\n",
    "print(f\"Number of principal components needed to retain 95% of the variance is equal to : {dim_95}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9392e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 24\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "columns = [f'PC{i+1}' for i in range(n_components)]\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102ce2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "      <th>PC17</th>\n",
       "      <th>PC18</th>\n",
       "      <th>PC19</th>\n",
       "      <th>PC20</th>\n",
       "      <th>PC21</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.323706</td>\n",
       "      <td>-0.438681</td>\n",
       "      <td>0.119638</td>\n",
       "      <td>-0.274475</td>\n",
       "      <td>0.504804</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>0.206205</td>\n",
       "      <td>0.718200</td>\n",
       "      <td>-0.214912</td>\n",
       "      <td>-0.460734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114322</td>\n",
       "      <td>0.689745</td>\n",
       "      <td>-0.951755</td>\n",
       "      <td>-1.353662</td>\n",
       "      <td>0.662644</td>\n",
       "      <td>0.759791</td>\n",
       "      <td>0.816179</td>\n",
       "      <td>0.682077</td>\n",
       "      <td>0.733266</td>\n",
       "      <td>-0.407738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.472416</td>\n",
       "      <td>-0.294095</td>\n",
       "      <td>0.132279</td>\n",
       "      <td>0.801410</td>\n",
       "      <td>-0.580910</td>\n",
       "      <td>-0.135913</td>\n",
       "      <td>-0.242820</td>\n",
       "      <td>0.557107</td>\n",
       "      <td>-0.054678</td>\n",
       "      <td>0.248475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070918</td>\n",
       "      <td>0.270543</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>-0.155087</td>\n",
       "      <td>-0.546761</td>\n",
       "      <td>0.086524</td>\n",
       "      <td>-0.541829</td>\n",
       "      <td>0.219267</td>\n",
       "      <td>0.041690</td>\n",
       "      <td>0.545476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.774979</td>\n",
       "      <td>-0.143406</td>\n",
       "      <td>1.062528</td>\n",
       "      <td>-0.384473</td>\n",
       "      <td>-0.482041</td>\n",
       "      <td>0.857686</td>\n",
       "      <td>-0.651046</td>\n",
       "      <td>0.099594</td>\n",
       "      <td>-2.926246</td>\n",
       "      <td>0.907234</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.054604</td>\n",
       "      <td>-0.375496</td>\n",
       "      <td>-1.172138</td>\n",
       "      <td>-1.260157</td>\n",
       "      <td>0.383679</td>\n",
       "      <td>0.492549</td>\n",
       "      <td>2.032578</td>\n",
       "      <td>1.550067</td>\n",
       "      <td>-0.673858</td>\n",
       "      <td>-1.506133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.171458</td>\n",
       "      <td>1.103605</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>1.032708</td>\n",
       "      <td>-1.468551</td>\n",
       "      <td>-0.670076</td>\n",
       "      <td>-2.401807</td>\n",
       "      <td>-1.595302</td>\n",
       "      <td>-0.124835</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.247022</td>\n",
       "      <td>0.701453</td>\n",
       "      <td>0.238503</td>\n",
       "      <td>-0.716555</td>\n",
       "      <td>0.457382</td>\n",
       "      <td>0.070336</td>\n",
       "      <td>0.059473</td>\n",
       "      <td>0.787761</td>\n",
       "      <td>-0.257404</td>\n",
       "      <td>0.402927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.065876</td>\n",
       "      <td>0.333169</td>\n",
       "      <td>-0.083784</td>\n",
       "      <td>-0.236284</td>\n",
       "      <td>0.559445</td>\n",
       "      <td>-0.355788</td>\n",
       "      <td>0.855319</td>\n",
       "      <td>0.019503</td>\n",
       "      <td>0.358221</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519914</td>\n",
       "      <td>-0.327568</td>\n",
       "      <td>-0.455114</td>\n",
       "      <td>-1.223756</td>\n",
       "      <td>0.613619</td>\n",
       "      <td>1.011752</td>\n",
       "      <td>0.644627</td>\n",
       "      <td>0.542530</td>\n",
       "      <td>-0.197150</td>\n",
       "      <td>-0.944399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-1.421777</td>\n",
       "      <td>-1.990802</td>\n",
       "      <td>-2.282983</td>\n",
       "      <td>-0.991219</td>\n",
       "      <td>0.191927</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>-0.153582</td>\n",
       "      <td>-1.841978</td>\n",
       "      <td>0.280496</td>\n",
       "      <td>1.132234</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.031302</td>\n",
       "      <td>-0.305649</td>\n",
       "      <td>4.938156</td>\n",
       "      <td>2.925600</td>\n",
       "      <td>6.651289</td>\n",
       "      <td>-2.941612</td>\n",
       "      <td>-1.513131</td>\n",
       "      <td>-1.593665</td>\n",
       "      <td>1.600975</td>\n",
       "      <td>-2.545939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.327532</td>\n",
       "      <td>-0.022614</td>\n",
       "      <td>1.006395</td>\n",
       "      <td>-0.669183</td>\n",
       "      <td>-0.352137</td>\n",
       "      <td>0.366783</td>\n",
       "      <td>-0.458915</td>\n",
       "      <td>0.692558</td>\n",
       "      <td>-0.875017</td>\n",
       "      <td>0.673398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388979</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.468159</td>\n",
       "      <td>-0.555374</td>\n",
       "      <td>0.436336</td>\n",
       "      <td>0.906179</td>\n",
       "      <td>1.558033</td>\n",
       "      <td>-0.087956</td>\n",
       "      <td>-1.425670</td>\n",
       "      <td>-0.253022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>-0.118065</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>1.010689</td>\n",
       "      <td>0.572298</td>\n",
       "      <td>-1.055025</td>\n",
       "      <td>0.952526</td>\n",
       "      <td>-1.939210</td>\n",
       "      <td>-0.394700</td>\n",
       "      <td>0.360316</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145770</td>\n",
       "      <td>-1.002949</td>\n",
       "      <td>-1.651097</td>\n",
       "      <td>0.981397</td>\n",
       "      <td>-0.988114</td>\n",
       "      <td>1.000923</td>\n",
       "      <td>-0.941341</td>\n",
       "      <td>0.861675</td>\n",
       "      <td>0.928754</td>\n",
       "      <td>0.441959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.415281</td>\n",
       "      <td>-0.104526</td>\n",
       "      <td>-0.074191</td>\n",
       "      <td>-0.324247</td>\n",
       "      <td>0.522271</td>\n",
       "      <td>0.103388</td>\n",
       "      <td>2.368417</td>\n",
       "      <td>0.164151</td>\n",
       "      <td>0.073613</td>\n",
       "      <td>-0.907173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>-0.116875</td>\n",
       "      <td>-2.202042</td>\n",
       "      <td>0.051574</td>\n",
       "      <td>0.193451</td>\n",
       "      <td>-0.275825</td>\n",
       "      <td>0.406662</td>\n",
       "      <td>1.530958</td>\n",
       "      <td>1.756351</td>\n",
       "      <td>-0.438564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>0.838265</td>\n",
       "      <td>-0.232402</td>\n",
       "      <td>-0.467684</td>\n",
       "      <td>-0.410960</td>\n",
       "      <td>-0.279761</td>\n",
       "      <td>-0.634405</td>\n",
       "      <td>-0.016050</td>\n",
       "      <td>-0.294729</td>\n",
       "      <td>-0.115652</td>\n",
       "      <td>-1.425724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190994</td>\n",
       "      <td>0.373169</td>\n",
       "      <td>-0.613631</td>\n",
       "      <td>0.335075</td>\n",
       "      <td>0.116111</td>\n",
       "      <td>0.762669</td>\n",
       "      <td>1.029705</td>\n",
       "      <td>-0.846303</td>\n",
       "      <td>-1.152415</td>\n",
       "      <td>-0.762998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0       0.323706 -0.438681  0.119638 -0.274475  0.504804  0.010446  0.206205   \n",
       "1      -0.472416 -0.294095  0.132279  0.801410 -0.580910 -0.135913 -0.242820   \n",
       "2       1.774979 -0.143406  1.062528 -0.384473 -0.482041  0.857686 -0.651046   \n",
       "3       0.245283  0.171458  1.103605  0.002308  1.032708 -1.468551 -0.670076   \n",
       "4      -0.065876  0.333169 -0.083784 -0.236284  0.559445 -0.355788  0.855319   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802 -1.421777 -1.990802 -2.282983 -0.991219  0.191927  0.011991 -0.153582   \n",
       "284803 -0.327532 -0.022614  1.006395 -0.669183 -0.352137  0.366783 -0.458915   \n",
       "284804 -0.118065  0.030470  1.010689  0.572298 -1.055025  0.952526 -1.939210   \n",
       "284805 -0.415281 -0.104526 -0.074191 -0.324247  0.522271  0.103388  2.368417   \n",
       "284806  0.838265 -0.232402 -0.467684 -0.410960 -0.279761 -0.634405 -0.016050   \n",
       "\n",
       "             PC8       PC9      PC10  ...      PC15      PC16      PC17  \\\n",
       "0       0.718200 -0.214912 -0.460734  ... -0.114322  0.689745 -0.951755   \n",
       "1       0.557107 -0.054678  0.248475  ...  0.070918  0.270543  0.003612   \n",
       "2       0.099594 -2.926246  0.907234  ... -1.054604 -0.375496 -1.172138   \n",
       "3      -2.401807 -1.595302 -0.124835  ... -1.247022  0.701453  0.238503   \n",
       "4       0.019503  0.358221  0.088716  ...  0.519914 -0.327568 -0.455114   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284802 -1.841978  0.280496  1.132234  ... -4.031302 -0.305649  4.938156   \n",
       "284803  0.692558 -0.875017  0.673398  ...  0.388979  0.383765 -1.468159   \n",
       "284804 -0.394700  0.360316  0.219944  ... -0.145770 -1.002949 -1.651097   \n",
       "284805  0.164151  0.073613 -0.907173  ...  0.004001 -0.116875 -2.202042   \n",
       "284806 -0.294729 -0.115652 -1.425724  ...  0.190994  0.373169 -0.613631   \n",
       "\n",
       "            PC18      PC19      PC20      PC21      PC22      PC23      PC24  \n",
       "0      -1.353662  0.662644  0.759791  0.816179  0.682077  0.733266 -0.407738  \n",
       "1      -0.155087 -0.546761  0.086524 -0.541829  0.219267  0.041690  0.545476  \n",
       "2      -1.260157  0.383679  0.492549  2.032578  1.550067 -0.673858 -1.506133  \n",
       "3      -0.716555  0.457382  0.070336  0.059473  0.787761 -0.257404  0.402927  \n",
       "4      -1.223756  0.613619  1.011752  0.644627  0.542530 -0.197150 -0.944399  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "284802  2.925600  6.651289 -2.941612 -1.513131 -1.593665  1.600975 -2.545939  \n",
       "284803 -0.555374  0.436336  0.906179  1.558033 -0.087956 -1.425670 -0.253022  \n",
       "284804  0.981397 -0.988114  1.000923 -0.941341  0.861675  0.928754  0.441959  \n",
       "284805  0.051574  0.193451 -0.275825  0.406662  1.530958  1.756351 -0.438564  \n",
       "284806  0.335075  0.116111  0.762669  1.029705 -0.846303 -1.152415 -0.762998  \n",
       "\n",
       "[284807 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579a768",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION using Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f50b29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8901/8901 [==============================] - 7s 783us/step - loss: 0.7643 - accuracy: 0.5687\n",
      "Epoch 2/50\n",
      "8901/8901 [==============================] - 7s 787us/step - loss: 0.7208 - accuracy: 0.6918\n",
      "Epoch 3/50\n",
      "8901/8901 [==============================] - 10s 1ms/step - loss: 0.7109 - accuracy: 0.7700\n",
      "Epoch 4/50\n",
      "8901/8901 [==============================] - 8s 845us/step - loss: 0.7076 - accuracy: 0.7845\n",
      "Epoch 5/50\n",
      "8901/8901 [==============================] - 6s 725us/step - loss: 0.7055 - accuracy: 0.7943\n",
      "Epoch 6/50\n",
      "8901/8901 [==============================] - 5s 562us/step - loss: 0.7049 - accuracy: 0.8154\n",
      "Epoch 7/50\n",
      "8901/8901 [==============================] - 5s 540us/step - loss: 0.7045 - accuracy: 0.8189\n",
      "Epoch 8/50\n",
      "8901/8901 [==============================] - 5s 553us/step - loss: 0.7042 - accuracy: 0.8217\n",
      "Epoch 9/50\n",
      "8901/8901 [==============================] - 5s 512us/step - loss: 0.7039 - accuracy: 0.8231\n",
      "Epoch 10/50\n",
      "8901/8901 [==============================] - 5s 539us/step - loss: 0.7038 - accuracy: 0.8246\n",
      "Epoch 11/50\n",
      "8901/8901 [==============================] - 5s 548us/step - loss: 0.7036 - accuracy: 0.8251\n",
      "Epoch 12/50\n",
      "8901/8901 [==============================] - 5s 552us/step - loss: 0.7046 - accuracy: 0.8207\n",
      "Epoch 13/50\n",
      "8901/8901 [==============================] - 5s 573us/step - loss: 0.7035 - accuracy: 0.8211\n",
      "Epoch 14/50\n",
      "8901/8901 [==============================] - 5s 575us/step - loss: 0.6991 - accuracy: 0.8146\n",
      "Epoch 15/50\n",
      "8901/8901 [==============================] - 5s 554us/step - loss: 0.6967 - accuracy: 0.8185\n",
      "Epoch 16/50\n",
      "8901/8901 [==============================] - 6s 695us/step - loss: 0.6961 - accuracy: 0.8226\n",
      "Epoch 17/50\n",
      "8901/8901 [==============================] - 5s 574us/step - loss: 0.6960 - accuracy: 0.8254\n",
      "Epoch 18/50\n",
      "8901/8901 [==============================] - 5s 518us/step - loss: 0.6948 - accuracy: 0.8219\n",
      "Epoch 19/50\n",
      "8901/8901 [==============================] - 5s 548us/step - loss: 0.6947 - accuracy: 0.8203\n",
      "Epoch 20/50\n",
      "8901/8901 [==============================] - 5s 572us/step - loss: 0.6958 - accuracy: 0.8293\n",
      "Epoch 21/50\n",
      "8901/8901 [==============================] - 6s 623us/step - loss: 0.6934 - accuracy: 0.8359\n",
      "Epoch 22/50\n",
      "8901/8901 [==============================] - 5s 541us/step - loss: 0.6957 - accuracy: 0.8294\n",
      "Epoch 23/50\n",
      "8901/8901 [==============================] - 5s 538us/step - loss: 0.6931 - accuracy: 0.8367\n",
      "Epoch 24/50\n",
      "8901/8901 [==============================] - 5s 518us/step - loss: 0.6980 - accuracy: 0.7561\n",
      "Epoch 25/50\n",
      "8901/8901 [==============================] - 5s 508us/step - loss: 0.6972 - accuracy: 0.8284\n",
      "Epoch 26/50\n",
      "8901/8901 [==============================] - 5s 576us/step - loss: 0.6953 - accuracy: 0.8309\n",
      "Epoch 27/50\n",
      "8901/8901 [==============================] - 5s 616us/step - loss: 0.6930 - accuracy: 0.8393\n",
      "Epoch 28/50\n",
      "8901/8901 [==============================] - 5s 553us/step - loss: 0.6929 - accuracy: 0.8387\n",
      "Epoch 29/50\n",
      "8901/8901 [==============================] - 5s 558us/step - loss: 0.6935 - accuracy: 0.8250\n",
      "Epoch 30/50\n",
      "8901/8901 [==============================] - 5s 552us/step - loss: 0.6926 - accuracy: 0.8420\n",
      "Epoch 31/50\n",
      "8901/8901 [==============================] - 5s 557us/step - loss: 0.6927 - accuracy: 0.8399\n",
      "Epoch 32/50\n",
      "8901/8901 [==============================] - 5s 580us/step - loss: 0.6906 - accuracy: 0.8509\n",
      "Epoch 33/50\n",
      "8901/8901 [==============================] - 5s 577us/step - loss: 0.6909 - accuracy: 0.8544\n",
      "Epoch 34/50\n",
      "8901/8901 [==============================] - 5s 594us/step - loss: 0.6896 - accuracy: 0.8602\n",
      "Epoch 35/50\n",
      "8901/8901 [==============================] - 5s 593us/step - loss: 0.6893 - accuracy: 0.8646\n",
      "Epoch 36/50\n",
      "8901/8901 [==============================] - 5s 598us/step - loss: 0.6896 - accuracy: 0.8589\n",
      "Epoch 37/50\n",
      "8901/8901 [==============================] - 5s 576us/step - loss: 0.6899 - accuracy: 0.8566\n",
      "Epoch 38/50\n",
      "8901/8901 [==============================] - 5s 552us/step - loss: 0.6895 - accuracy: 0.8592\n",
      "Epoch 39/50\n",
      "8901/8901 [==============================] - 6s 658us/step - loss: 0.6891 - accuracy: 0.8626\n",
      "Epoch 40/50\n",
      "8901/8901 [==============================] - 5s 605us/step - loss: 0.6895 - accuracy: 0.8603\n",
      "Epoch 41/50\n",
      "8901/8901 [==============================] - 7s 735us/step - loss: 0.6892 - accuracy: 0.8628\n",
      "Epoch 42/50\n",
      "8901/8901 [==============================] - 5s 576us/step - loss: 0.6890 - accuracy: 0.8626\n",
      "Epoch 43/50\n",
      "8901/8901 [==============================] - 8s 843us/step - loss: 0.6888 - accuracy: 0.8662\n",
      "Epoch 44/50\n",
      "8901/8901 [==============================] - 6s 673us/step - loss: 0.6893 - accuracy: 0.8625\n",
      "Epoch 45/50\n",
      "8901/8901 [==============================] - 5s 541us/step - loss: 0.6888 - accuracy: 0.8615\n",
      "Epoch 46/50\n",
      "8901/8901 [==============================] - 5s 560us/step - loss: 0.6887 - accuracy: 0.8663\n",
      "Epoch 47/50\n",
      "8901/8901 [==============================] - 5s 555us/step - loss: 0.6887 - accuracy: 0.8649\n",
      "Epoch 48/50\n",
      "8901/8901 [==============================] - 6s 622us/step - loss: 0.6886 - accuracy: 0.8644\n",
      "Epoch 49/50\n",
      "8901/8901 [==============================] - 5s 560us/step - loss: 0.6887 - accuracy: 0.8654\n",
      "Epoch 50/50\n",
      "8901/8901 [==============================] - 5s 549us/step - loss: 0.6886 - accuracy: 0.8665\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "input_dim = X.shape[1] \n",
    "encoding_dim = 20  \n",
    "\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Encoder layers\n",
    "autoencoder.add(Dense(24, input_shape=(input_dim,), activation='relu'))\n",
    "autoencoder.add(Dense(encoding_dim, activation='relu'))\n",
    "\n",
    "# Decoder layers\n",
    "autoencoder.add(Dense(24, activation='relu'))\n",
    "autoencoder.add(Dense(input_dim, activation='sigmoid'))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error',  metrics=['accuracy'])\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_scaled, X_scaled, epochs=50, batch_size=32, shuffle=True)\n",
    "\n",
    "# Extract features using the encoder part of the autoencoder\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.layers[1].output)\n",
    "X_encoded = encoder.predict(X_scaled)\n",
    "\n",
    "\n",
    "# Create a DataFrame with the encoded features\n",
    "columns = [f'AEC{i+1}' for i in range(encoding_dim)]\n",
    "df_AEC = pd.DataFrame(data=X_encoded, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08988b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AEC1</th>\n",
       "      <th>AEC2</th>\n",
       "      <th>AEC3</th>\n",
       "      <th>AEC4</th>\n",
       "      <th>AEC5</th>\n",
       "      <th>AEC6</th>\n",
       "      <th>AEC7</th>\n",
       "      <th>AEC8</th>\n",
       "      <th>AEC9</th>\n",
       "      <th>AEC10</th>\n",
       "      <th>AEC11</th>\n",
       "      <th>AEC12</th>\n",
       "      <th>AEC13</th>\n",
       "      <th>AEC14</th>\n",
       "      <th>AEC15</th>\n",
       "      <th>AEC16</th>\n",
       "      <th>AEC17</th>\n",
       "      <th>AEC18</th>\n",
       "      <th>AEC19</th>\n",
       "      <th>AEC20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.399997</td>\n",
       "      <td>3.350268</td>\n",
       "      <td>2.070490</td>\n",
       "      <td>3.923510</td>\n",
       "      <td>5.804910</td>\n",
       "      <td>4.690724</td>\n",
       "      <td>3.577381</td>\n",
       "      <td>2.624564</td>\n",
       "      <td>4.237773</td>\n",
       "      <td>6.460435</td>\n",
       "      <td>7.349691</td>\n",
       "      <td>5.433467</td>\n",
       "      <td>5.516147</td>\n",
       "      <td>3.683073</td>\n",
       "      <td>6.456587</td>\n",
       "      <td>5.324872</td>\n",
       "      <td>6.119384</td>\n",
       "      <td>4.732521</td>\n",
       "      <td>4.273170</td>\n",
       "      <td>5.237740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.259123</td>\n",
       "      <td>3.136459</td>\n",
       "      <td>6.720217</td>\n",
       "      <td>2.821558</td>\n",
       "      <td>4.174748</td>\n",
       "      <td>4.257555</td>\n",
       "      <td>3.733523</td>\n",
       "      <td>1.550718</td>\n",
       "      <td>6.093435</td>\n",
       "      <td>2.599350</td>\n",
       "      <td>5.035872</td>\n",
       "      <td>3.766545</td>\n",
       "      <td>1.417892</td>\n",
       "      <td>3.426452</td>\n",
       "      <td>2.025512</td>\n",
       "      <td>4.526514</td>\n",
       "      <td>5.522000</td>\n",
       "      <td>6.920812</td>\n",
       "      <td>3.207294</td>\n",
       "      <td>2.153465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.514083</td>\n",
       "      <td>5.792971</td>\n",
       "      <td>2.072207</td>\n",
       "      <td>10.887881</td>\n",
       "      <td>10.615773</td>\n",
       "      <td>6.876300</td>\n",
       "      <td>4.025495</td>\n",
       "      <td>3.751724</td>\n",
       "      <td>10.486926</td>\n",
       "      <td>4.998475</td>\n",
       "      <td>7.852761</td>\n",
       "      <td>6.698345</td>\n",
       "      <td>5.246704</td>\n",
       "      <td>2.677579</td>\n",
       "      <td>8.896847</td>\n",
       "      <td>9.784435</td>\n",
       "      <td>6.266364</td>\n",
       "      <td>11.121435</td>\n",
       "      <td>5.850774</td>\n",
       "      <td>5.975783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.523297</td>\n",
       "      <td>9.451435</td>\n",
       "      <td>1.764440</td>\n",
       "      <td>7.964665</td>\n",
       "      <td>5.250674</td>\n",
       "      <td>5.619663</td>\n",
       "      <td>3.174740</td>\n",
       "      <td>4.403363</td>\n",
       "      <td>7.724745</td>\n",
       "      <td>6.537484</td>\n",
       "      <td>3.946452</td>\n",
       "      <td>5.944974</td>\n",
       "      <td>2.434571</td>\n",
       "      <td>5.874364</td>\n",
       "      <td>3.957994</td>\n",
       "      <td>5.970232</td>\n",
       "      <td>5.465010</td>\n",
       "      <td>5.257945</td>\n",
       "      <td>4.024283</td>\n",
       "      <td>4.477828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.757082</td>\n",
       "      <td>6.985779</td>\n",
       "      <td>0.835903</td>\n",
       "      <td>3.197806</td>\n",
       "      <td>5.577367</td>\n",
       "      <td>5.815514</td>\n",
       "      <td>6.421628</td>\n",
       "      <td>4.234631</td>\n",
       "      <td>4.745263</td>\n",
       "      <td>6.917017</td>\n",
       "      <td>7.637008</td>\n",
       "      <td>6.072339</td>\n",
       "      <td>5.265399</td>\n",
       "      <td>1.374329</td>\n",
       "      <td>7.120970</td>\n",
       "      <td>4.510016</td>\n",
       "      <td>8.279637</td>\n",
       "      <td>4.479966</td>\n",
       "      <td>4.052859</td>\n",
       "      <td>2.789463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>15.651002</td>\n",
       "      <td>6.476346</td>\n",
       "      <td>3.699875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.939553</td>\n",
       "      <td>9.251195</td>\n",
       "      <td>7.082742</td>\n",
       "      <td>6.959209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.221968</td>\n",
       "      <td>11.872884</td>\n",
       "      <td>3.306141</td>\n",
       "      <td>3.567354</td>\n",
       "      <td>5.266860</td>\n",
       "      <td>8.708531</td>\n",
       "      <td>15.358184</td>\n",
       "      <td>15.530862</td>\n",
       "      <td>5.759624</td>\n",
       "      <td>8.865960</td>\n",
       "      <td>5.626585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>2.650416</td>\n",
       "      <td>5.250567</td>\n",
       "      <td>2.468125</td>\n",
       "      <td>5.248614</td>\n",
       "      <td>7.065758</td>\n",
       "      <td>9.161251</td>\n",
       "      <td>6.863231</td>\n",
       "      <td>3.456936</td>\n",
       "      <td>4.928693</td>\n",
       "      <td>5.981474</td>\n",
       "      <td>6.274726</td>\n",
       "      <td>3.361331</td>\n",
       "      <td>4.597137</td>\n",
       "      <td>1.619313</td>\n",
       "      <td>5.085045</td>\n",
       "      <td>6.845173</td>\n",
       "      <td>7.207296</td>\n",
       "      <td>7.560125</td>\n",
       "      <td>4.018367</td>\n",
       "      <td>4.038968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>5.080348</td>\n",
       "      <td>1.933554</td>\n",
       "      <td>9.846227</td>\n",
       "      <td>5.412540</td>\n",
       "      <td>3.495756</td>\n",
       "      <td>3.999190</td>\n",
       "      <td>6.130712</td>\n",
       "      <td>8.824333</td>\n",
       "      <td>12.437031</td>\n",
       "      <td>5.662713</td>\n",
       "      <td>4.412973</td>\n",
       "      <td>3.483286</td>\n",
       "      <td>1.308554</td>\n",
       "      <td>2.085100</td>\n",
       "      <td>5.046151</td>\n",
       "      <td>6.780863</td>\n",
       "      <td>9.141593</td>\n",
       "      <td>10.119125</td>\n",
       "      <td>3.307288</td>\n",
       "      <td>8.781593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>6.597059</td>\n",
       "      <td>3.040435</td>\n",
       "      <td>1.602706</td>\n",
       "      <td>3.042363</td>\n",
       "      <td>4.917971</td>\n",
       "      <td>5.869171</td>\n",
       "      <td>4.211174</td>\n",
       "      <td>5.544131</td>\n",
       "      <td>5.608936</td>\n",
       "      <td>7.894925</td>\n",
       "      <td>8.602537</td>\n",
       "      <td>9.092431</td>\n",
       "      <td>4.824016</td>\n",
       "      <td>3.117891</td>\n",
       "      <td>9.164093</td>\n",
       "      <td>5.517907</td>\n",
       "      <td>10.663144</td>\n",
       "      <td>4.220461</td>\n",
       "      <td>6.001402</td>\n",
       "      <td>7.662840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>5.838974</td>\n",
       "      <td>7.523586</td>\n",
       "      <td>2.503640</td>\n",
       "      <td>3.978446</td>\n",
       "      <td>4.985472</td>\n",
       "      <td>6.371808</td>\n",
       "      <td>8.297415</td>\n",
       "      <td>4.321103</td>\n",
       "      <td>4.862808</td>\n",
       "      <td>7.488173</td>\n",
       "      <td>6.475964</td>\n",
       "      <td>6.899802</td>\n",
       "      <td>5.837553</td>\n",
       "      <td>3.894532</td>\n",
       "      <td>8.486412</td>\n",
       "      <td>6.759908</td>\n",
       "      <td>7.059851</td>\n",
       "      <td>7.576933</td>\n",
       "      <td>4.416987</td>\n",
       "      <td>4.911249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AEC1      AEC2      AEC3       AEC4       AEC5      AEC6  \\\n",
       "0        3.399997  3.350268  2.070490   3.923510   5.804910  4.690724   \n",
       "1        3.259123  3.136459  6.720217   2.821558   4.174748  4.257555   \n",
       "2        5.514083  5.792971  2.072207  10.887881  10.615773  6.876300   \n",
       "3        4.523297  9.451435  1.764440   7.964665   5.250674  5.619663   \n",
       "4        3.757082  6.985779  0.835903   3.197806   5.577367  5.815514   \n",
       "...           ...       ...       ...        ...        ...       ...   \n",
       "284802  15.651002  6.476346  3.699875   0.000000   0.939553  9.251195   \n",
       "284803   2.650416  5.250567  2.468125   5.248614   7.065758  9.161251   \n",
       "284804   5.080348  1.933554  9.846227   5.412540   3.495756  3.999190   \n",
       "284805   6.597059  3.040435  1.602706   3.042363   4.917971  5.869171   \n",
       "284806   5.838974  7.523586  2.503640   3.978446   4.985472  6.371808   \n",
       "\n",
       "            AEC7      AEC8       AEC9     AEC10      AEC11     AEC12  \\\n",
       "0       3.577381  2.624564   4.237773  6.460435   7.349691  5.433467   \n",
       "1       3.733523  1.550718   6.093435  2.599350   5.035872  3.766545   \n",
       "2       4.025495  3.751724  10.486926  4.998475   7.852761  6.698345   \n",
       "3       3.174740  4.403363   7.724745  6.537484   3.946452  5.944974   \n",
       "4       6.421628  4.234631   4.745263  6.917017   7.637008  6.072339   \n",
       "...          ...       ...        ...       ...        ...       ...   \n",
       "284802  7.082742  6.959209   0.000000  2.221968  11.872884  3.306141   \n",
       "284803  6.863231  3.456936   4.928693  5.981474   6.274726  3.361331   \n",
       "284804  6.130712  8.824333  12.437031  5.662713   4.412973  3.483286   \n",
       "284805  4.211174  5.544131   5.608936  7.894925   8.602537  9.092431   \n",
       "284806  8.297415  4.321103   4.862808  7.488173   6.475964  6.899802   \n",
       "\n",
       "           AEC13     AEC14     AEC15      AEC16      AEC17      AEC18  \\\n",
       "0       5.516147  3.683073  6.456587   5.324872   6.119384   4.732521   \n",
       "1       1.417892  3.426452  2.025512   4.526514   5.522000   6.920812   \n",
       "2       5.246704  2.677579  8.896847   9.784435   6.266364  11.121435   \n",
       "3       2.434571  5.874364  3.957994   5.970232   5.465010   5.257945   \n",
       "4       5.265399  1.374329  7.120970   4.510016   8.279637   4.479966   \n",
       "...          ...       ...       ...        ...        ...        ...   \n",
       "284802  3.567354  5.266860  8.708531  15.358184  15.530862   5.759624   \n",
       "284803  4.597137  1.619313  5.085045   6.845173   7.207296   7.560125   \n",
       "284804  1.308554  2.085100  5.046151   6.780863   9.141593  10.119125   \n",
       "284805  4.824016  3.117891  9.164093   5.517907  10.663144   4.220461   \n",
       "284806  5.837553  3.894532  8.486412   6.759908   7.059851   7.576933   \n",
       "\n",
       "           AEC19     AEC20  \n",
       "0       4.273170  5.237740  \n",
       "1       3.207294  2.153465  \n",
       "2       5.850774  5.975783  \n",
       "3       4.024283  4.477828  \n",
       "4       4.052859  2.789463  \n",
       "...          ...       ...  \n",
       "284802  8.865960  5.626585  \n",
       "284803  4.018367  4.038968  \n",
       "284804  3.307288  8.781593  \n",
       "284805  6.001402  7.662840  \n",
       "284806  4.416987  4.911249  \n",
       "\n",
       "[284807 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_AEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b1c19",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION using Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522c1ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 2.399999643465378e-11\n",
      "Epoch [2/3], Loss: 2.399999643465378e-11\n",
      "Epoch [3/3], Loss: 2.399999643465378e-11\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.fc(x1)\n",
    "        out2 = self.fc(x2)\n",
    "        return out1, out2\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive\n",
    "\n",
    "siamese_network = SiameseNetwork(input_size=29, output_size=24)\n",
    "contrastive_loss = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(siamese_network.parameters(), lr=0.001)\n",
    "\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x1 = self.X[index]\n",
    "        label = self.y[index]\n",
    "        x2 = self.X[torch.randint(len(self.X), (1,)).item()]\n",
    "        return x1, x2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = SiameseDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for x1, x2, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = siamese_network(x1, x2)\n",
    "        loss = contrastive_loss(output1, output2, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "siamese_network.eval()\n",
    "with torch.no_grad():\n",
    "    num_samples = len(X_tensor)\n",
    "    indices = torch.randint(num_samples, (num_samples,))\n",
    "    x1_eval = X_tensor\n",
    "    x2_eval = X_tensor[indices]\n",
    "\n",
    "    all_outputs, _ = siamese_network(x1_eval, x2_eval)\n",
    "\n",
    "columns = [f'CL{i+1}' for i in range(24)]\n",
    "df_CL = pd.DataFrame(data=all_outputs, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25fe4e9",
   "metadata": {},
   "source": [
    "# Treating the minority class as an anomaly and using anomaly detection techniques for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59efd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[284234     81]\n",
      " [   104    388]]\n",
      "Calinski-Harabasz Index: 576644.6645222094\n",
      "Homogeneity: 0.684416603623728\n",
      "Completeness: 0.7133367943177018\n",
      "V-Measure: 0.6985775126367709\n"
     ]
    }
   ],
   "source": [
    "# For CL\n",
    "\n",
    "clf = IsolationForest(contamination='auto', random_state=42)\n",
    "clf.fit(df_CL)\n",
    "\n",
    "y_pred = clf.predict(df_CL)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_CL, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0a105e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[272137  12178]\n",
      " [    61    431]]\n",
      "Calinski-Harabasz Index: 6466.791582772693\n",
      "Homogeneity: 0.3228183549777148\n",
      "Completeness: 0.022640559268896732\n",
      "V-Measure: 0.04231350124456883\n"
     ]
    }
   ],
   "source": [
    "# For PCA\n",
    "\n",
    "clf = IsolationForest(contamination='auto', random_state=42)\n",
    "clf.fit(df_pca)\n",
    "\n",
    "y_pred = clf.predict(df_pca)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_pca, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2a809d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[266603  17712]\n",
      " [    55    437]]\n",
      "Calinski-Harabasz Index: 40996.81124719068\n",
      "Homogeneity: 0.2870116315520225\n",
      "Completeness: 0.015391673809798653\n",
      "V-Measure: 0.02921654184421869\n"
     ]
    }
   ],
   "source": [
    "# For Auto-encoder\n",
    "\n",
    "clf = IsolationForest(contamination='auto', random_state=42)\n",
    "clf.fit(df_AEC)\n",
    "\n",
    "y_pred = clf.predict(df_AEC)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_AEC, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00a89039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[274629   9686]\n",
      " [    90    402]]\n",
      "Calinski-Harabasz Index: 6009.115262568077\n",
      "Homogeneity: 0.3092113693388358\n",
      "Completeness: 0.02567836066574896\n",
      "V-Measure: 0.04741883881434067\n"
     ]
    }
   ],
   "source": [
    "# For without feature selection\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "clf = IsolationForest(contamination='auto', random_state=42)\n",
    "clf.fit(X_scaled)\n",
    "\n",
    "y_pred = clf.predict(X_scaled)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(X_scaled, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16bf6f",
   "metadata": {},
   "source": [
    "# Using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a89402b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[284254     61]\n",
      " [   126    366]]\n",
      "Calinski-Harabasz Index: 604083.0909926749\n",
      "Homogeneity: 0.6481757465866271\n",
      "Completeness: 0.7327267883904061\n",
      "V-Measure: 0.687862786951683\n"
     ]
    }
   ],
   "source": [
    "# For CL\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "y_pred = kmeans.fit_predict(df_CL)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_CL, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad14f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[278787   5528]\n",
      " [   473     19]]\n",
      "Calinski-Harabasz Index: 11845.237043824596\n",
      "Homogeneity: 0.0010186715155261407\n",
      "Completeness: 0.0001349258384561447\n",
      "V-Measure: 0.00023828956935327151\n"
     ]
    }
   ],
   "source": [
    "# For PCA\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "y_pred = kmeans.fit_predict(df_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_pca, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a47fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[282748   1567]\n",
      " [   121    371]]\n",
      "Calinski-Harabasz Index: 70191.20649007458\n",
      "Homogeneity: 0.4460768947454995\n",
      "Completeness: 0.13922631258044968\n",
      "V-Measure: 0.21221698567651034\n"
     ]
    }
   ],
   "source": [
    "# For Auto-encoder\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "y_pred = kmeans.fit_predict(df_AEC)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_AEC, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad5f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[238086  46229]\n",
      " [   311    181]]\n",
      "Calinski-Harabasz Index: 10257.48201880488\n",
      "Homogeneity: 0.016621379589252205\n",
      "Completeness: 0.0004754097641289101\n",
      "V-Measure: 0.0009243801261972914\n"
     ]
    }
   ],
   "source": [
    "# For without feature selection\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(X_scaled, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1f2de",
   "metadata": {},
   "source": [
    "# For GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "679a718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[284233     82]\n",
      " [   104    388]]\n",
      "Calinski-Harabasz Index: 573126.022428341\n",
      "Homogeneity: 0.6839331476117575\n",
      "Completeness: 0.7115209833205699\n",
      "V-Measure: 0.6974543626011157\n"
     ]
    }
   ],
   "source": [
    "# For CL\n",
    "n_clusters = 2\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "y_pred = gmm.fit_predict(df_CL)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_CL, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e74cd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[178110 106205]\n",
      " [   449     43]]\n",
      "Calinski-Harabasz Index: 8843.722812584565\n",
      "Homogeneity: 0.029359137356640582\n",
      "Completeness: 0.000565114242105322\n",
      "V-Measure: 0.0011088843175519427\n"
     ]
    }
   ],
   "source": [
    "# For PCA\n",
    "n_clusters = 2\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "y_pred = gmm.fit_predict(df_pca)\n",
    "\n",
    "# Evaluate t he model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_pca, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71589fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[226150  58165]\n",
      " [    30    462]]\n",
      "Calinski-Harabasz Index: 16680.445990834392\n",
      "Homogeneity: 0.17275248258121617\n",
      "Completeness: 0.004320372168367781\n",
      "V-Measure: 0.008429920202233368\n"
     ]
    }
   ],
   "source": [
    "# For Auto-encoder\n",
    "n_clusters = 2\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "y_pred = gmm.fit_predict(df_AEC)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_AEC, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f823d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[179609 104706]\n",
      " [    51    441]]\n",
      "Calinski-Harabasz Index: 5672.355392565628\n",
      "Homogeneity: 0.08272935149907325\n",
      "Completeness: 0.0015973318338359053\n",
      "V-Measure: 0.0031341497499759664\n"
     ]
    }
   ],
   "source": [
    "# For without feature selection\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_clusters = 2\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "y_pred = gmm.fit_predict(X_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(X_scaled, y_pred)\n",
    "homogeneity = homogeneity_score(y, y_pred)\n",
    "completeness = completeness_score(y, y_pred)\n",
    "v_measure = v_measure_score(y, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc14173",
   "metadata": {},
   "source": [
    "# For OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93d7c452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[     9 284306]\n",
      " [     1    491]]\n",
      "Calinski-Harabasz Index: 106.4752619634365\n",
      "Homogeneity: 0.0008634643551991421\n",
      "Completeness: 0.027776611284443847\n",
      "V-Measure: 0.0016748638553971706\n"
     ]
    }
   ],
   "source": [
    "# For CL\n",
    "clf = OneClassSVM(nu=0.005)\n",
    "y_pred = clf.fit_predict(df_CL)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_CL, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f5772ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[282723   1592]\n",
      " [   367    125]]\n",
      "Calinski-Harabasz Index: 3592.853097597378\n",
      "Homogeneity: 0.10127948607349785\n",
      "Completeness: 0.03496980220128557\n",
      "V-Measure: 0.051988874802710694\n"
     ]
    }
   ],
   "source": [
    "# For PCA\n",
    "clf = OneClassSVM(nu=0.005)\n",
    "y_pred = clf.fit_predict(df_pca)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_pca, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90eff7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[283134   1181]\n",
      " [   253    239]]\n",
      "Calinski-Harabasz Index: 31475.050924197007\n",
      "Homogeneity: 0.2619127472749787\n",
      "Completeness: 0.10604163507409295\n",
      "V-Measure: 0.15096249589677702\n"
     ]
    }
   ],
   "source": [
    "# For Auto-encoder\n",
    "clf = OneClassSVM(nu=0.005)\n",
    "y_pred = clf.fit_predict(df_AEC)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(df_AEC, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc16be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[282718   1597]\n",
      " [   360    132]]\n",
      "Calinski-Harabasz Index: 2971.076154107819\n",
      "Homogeneity: 0.10902573188917995\n",
      "Completeness: 0.03742596207650297\n",
      "V-Measure: 0.055723396521498235\n"
     ]
    }
   ],
   "source": [
    "# For without feature selection\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "n_clusters = 2\n",
    "clf = OneClassSVM(nu=0.005)\n",
    "y_pred = clf.fit_predict(X_scaled)\n",
    "\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred_binary))\n",
    "\n",
    "# Print evaluation metrics\n",
    "calinski_harabasz_index = calinski_harabasz_score(X_scaled, y_pred_binary)\n",
    "homogeneity = homogeneity_score(y, y_pred_binary)\n",
    "completeness = completeness_score(y, y_pred_binary)\n",
    "v_measure = v_measure_score(y, y_pred_binary)\n",
    "\n",
    "\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz_index}\")\n",
    "print(f\"Homogeneity: {homogeneity}\")\n",
    "print(f\"Completeness: {completeness}\")\n",
    "print(f\"V-Measure: {v_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0814da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM, Kmeans, IsolationForest, OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b2928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
